<!DOCTYPE html><html lang="en,default"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.2.1"><link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico"><link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="/lib/animate-css/animate.min.css"><script class="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"hanielxx.com",root:"/",scheme:"Mala",version:"8.0.0-rc.4",exturl:!1,sidebar:{position:"right",display:"post",padding:18,offset:12},copycode:!1,bookmark:{enable:!0,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"fadeInDown",post_body:"fadeInDown",coll_header:"fadeInLeft",sidebar:"fadeInUp"}},prism:!1,path:"search.xml"}</script><meta name="description" content="# 聚类 ## 聚类定义 　　聚类(Clustering)，指的是一种学习方式（操作方式），即把物理或者抽象对象的集合分组为由彼此的对象组成的多个类的分析过程。"><meta property="og:type" content="article"><meta property="og:title" content="聚类和K-Means算法"><meta property="og:url" content="https://hanielxx.com/MachineLearning/2018-09-10-machinelearning-cluster-k-means"><meta property="og:site_name" content="Catch Your Dream"><meta property="og:description" content="# 聚类 ## 聚类定义 　　聚类(Clustering)，指的是一种学习方式（操作方式），即把物理或者抽象对象的集合分组为由彼此的对象组成的多个类的分析过程。"><meta property="og:locale" content="en_US"><meta property="article:published_time" content="2018-09-10T10:08:12.000Z"><meta property="article:modified_time" content="2020-11-14T17:25:54.714Z"><meta property="article:author" content="Hanielxx"><meta property="article:tag" content="MachineLearning"><meta property="article:tag" content="Learning"><meta property="article:tag" content="Python"><meta property="article:tag" content="Clustering"><meta property="article:tag" content="K-Means"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://hanielxx.com/MachineLearning/2018-09-10-machinelearning-cluster-k-means.html"><script class="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"en"}</script><title>聚类和K-Means算法 | Catch Your Dream</title><noscript><style>body{margin-top:2rem}.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header,.use-motion .sidebar{visibility:visible}.use-motion .footer,.use-motion .header,.use-motion .site-brand-container .toggle{opacity:initial}.use-motion .custom-logo-image,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line{transform:scaleX(1)}.search-pop-overlay,.sidebar-nav{display:none}.sidebar-panel{display:block}</style></noscript><link rel="alternate" href="/atom.xml" title="Catch Your Dream" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><main class="main"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="Toggle navigation bar"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><h1 class="site-title">Catch Your Dream</h1><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-algorithm"><a href="/tags/Algorithm/" rel="section"><i class="fa fa-code fa-fw"></i>Algorithm</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="Searching..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">Table of Contents</li><li class="sidebar-nav-overview">Overview</li></ul><section class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#聚类算法分类"><span class="nav-number">1.</span> <span class="nav-text">聚类算法分类</span></a></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#常用距离算法"><span class="nav-number"></span> <span class="nav-text">常用距离算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#欧氏距离"><span class="nav-number">1.</span> <span class="nav-text">欧氏距离</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#曼哈顿距离"><span class="nav-number">2.</span> <span class="nav-text">曼哈顿距离</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#k-means算法"><span class="nav-number"></span> <span class="nav-text">k-means算法</span></a></li></div></section><section class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Hanielxx" src="/uploads/avatar.jpg"><p class="site-author-name" itemprop="name">Hanielxx</p><div class="site-description" itemprop="description">Hanielxx | Blog</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">102</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">categories</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">129</span> <span class="site-state-item-name">tags</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/HanielF" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;HanielF" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:hanielxx@outlook.com" title="E-Mail → mailto:hanielxx@outlook.com" rel="external nofollow noopener noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div></section></div></aside><div id="sidebar-dimmer"></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a role="button" class="book-mark-link book-mark-link-fixed"></a> <a href="https://github.com/HanielF" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="external nofollow noopener noreferrer" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><noscript><div id="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en"><link itemprop="mainEntityOfPage" href="https://hanielxx.com/MachineLearning/2018-09-10-machinelearning-cluster-k-means"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar.jpg"><meta itemprop="name" content="Hanielxx"><meta itemprop="description" content="Hanielxx | Blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Catch Your Dream"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">聚类和K-Means算法</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Created: 2018-09-10 18:08:12" itemprop="dateCreated datePublished" datetime="2018-09-10T18:08:12+08:00">2018-09-10</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">Edited on</span> <time title="Modified: 2020-11-15 01:25:54" itemprop="dateModified" datetime="2020-11-15T01:25:54+08:00">2020-11-15</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">In</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MachineLearning/" itemprop="url" rel="index"><span itemprop="name">MachineLearning</span></a></span></span><br><span class="post-meta-item" title="Symbols count in article"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">Symbols count in article: </span><span>2.2k</span> </span><span class="post-meta-item" title="Reading time"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">Reading time &asymp;</span> <span>6 mins.</span></span></div></header><div class="post-body" itemprop="articleBody"><meta name="referrer" content="no-referrer"># 聚类 ## 聚类定义 　　聚类(Clustering)，指的是一种学习方式（操作方式），即把物理或者抽象对象的集合分组为由彼此的对象组成的多个类的分析过程。<a id="more"></a><div class="note info"><p>聚类属于无监督机器学习，简言之就是把特征形态相同的或者近似的划分在一个概念下，聚集为一组。</p><p>聚类在实际的应用中中亦是非常广泛的，如：市场细分（Market segmentation）、社交圈分析（social network analysis）、集群计算（organize computing clusters）、天体数据分析（astronomical data analysis）等</p></div><h2 id="聚类算法分类"><a href="#聚类算法分类" class="headerlink" title="聚类算法分类"></a>聚类算法分类</h2><p>　　主要的聚类主要的聚类算法可以划分为如下几类：划分方法、层次方法、基于密度的方法、基于网格的方法以及基于模型的方法。</p><p>　　每一类中都存在着得到广泛应用的算法，例如：划分方法中的k-means聚类算法、层次方法中的凝聚型层次聚类算法、基于模型方法中的神经网络聚类算法等</p><p>　　但是上述的都是硬聚类，即每一个数据只能被归为一类，还有一种是模糊聚类。<br>　　模糊聚类通过隶属函数来确定每个数据隶属于各个簇的程度，而不是将一个数据对象硬性地归类到某一簇中。</p><h1 id="常用距离算法"><a href="#常用距离算法" class="headerlink" title="常用距离算法"></a>常用距离算法</h1><h2 id="欧氏距离"><a href="#欧氏距离" class="headerlink" title="欧氏距离"></a>欧氏距离</h2><p>　　欧氏距离是最直观的距离度量方法，通常就是学过的两点间距离，可以用在多维。</p><ul><li>二维平面上点a(x1,y1)与b(x2,y2)间的欧氏距离:<br>$$ d_{12} = \sqrt{(x_1-x_2)^2+(y_1-y_2)^2} $$</li><li>三维空间点a(x1,y1,z1)与b(x2,y2,z2)间的欧氏距离:<br>$$ d{12} = \sqrt{(x_1-x_2)^2+(y_1-y_2)^2+(z_1-z_2)^2} $$</li><li>更高维的计算类似二维三维</li></ul><h2 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h2><p>　　不再是两点间连线的那种，是类似九宫格的走法，只能直线和直角拐弯。又叫做“城市街区距离”。</p><ul><li>二维平面两点a(x1,y1)与b(x2,y2)间的曼哈顿距离：<br>$$ d_12 = |x_1-x_2|+|y_1-y_2| $$</li><li>三维和其他维类似</li></ul><div class="note info"><p>　　除了这两种还有余弦距离和切比雪夫距离等，这里不展开说。采用不同的距离度量方法对结果有很大的影响。</p></div><h1 id="k-means算法"><a href="#k-means算法" class="headerlink" title="k-means算法"></a>k-means算法</h1><p>思想大致是:</p><ul><li>1.　先随机选k个质心</li><li>2.　对每个点计算其到各个质心的距离</li><li>3.　选距离最近的，把这个点归为这个质心的一类，形成k个簇</li><li>4.　然后对于每个簇，计算其中每个点到质心的平均距离</li><li>5.　然后把这个作为这个簇的新的质心,进行第二步</li><li>6.　直到簇不怎么发生变化或者达到了预设的最大迭代次数，停止</li></ul><p>　主要函数如下:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//k-means聚类</span></span><br><span class="line"><span class="function"><span class="built_in">vector</span>&lt;Cluster&gt; <span class="title">k_means</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt;trans,<span class="keyword">int</span> k,<span class="keyword">int</span> counts)</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="built_in">vector</span>&lt;Cluster&gt; <span class="title">clusters</span><span class="params">(k)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> row = trans.<span class="built_in">size</span>();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> col = trans[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">//随机初始化聚类中心</span></span><br><span class="line">  srand((<span class="keyword">int</span>)time(<span class="number">0</span>));</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;k;i++)&#123;</span><br><span class="line">    <span class="keyword">int</span> center = rand()%trans.<span class="built_in">size</span>();</span><br><span class="line">    clusters[i].center=trans[center]; </span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//迭代counts次</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> cnt = <span class="number">0</span>;cnt&lt;counts;cnt++)&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//清空样本空间</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;k;i++)</span><br><span class="line">      clusters[i].samples.<span class="built_in">clear</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计算样本属于的簇</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;row;i++)&#123;</span><br><span class="line">      <span class="keyword">int</span> tmp_center = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">int</span> minal = cal_distance(trans[i],clusters[tmp_center].center);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;k;j++)&#123;</span><br><span class="line">        <span class="keyword">int</span> distance = cal_distance(trans[i],clusters[j].center);</span><br><span class="line">        <span class="keyword">if</span>(distance&lt;minal)&#123;</span><br><span class="line">          tmp_center = j;</span><br><span class="line">          minal = distance;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      clusters[tmp_center].samples.push_back(i);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//重新计算簇中心</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;k;i++)&#123;</span><br><span class="line">      <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> m=<span class="number">0</span>;m&lt;trans[<span class="number">0</span>].<span class="built_in">size</span>();m++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;clusters[i].samples.<span class="built_in">size</span>();j++)&#123;</span><br><span class="line">          <span class="comment">//cout&lt;&lt;"sum+=: "&lt;&lt;trans[clusters[i].samples[j]][m];</span></span><br><span class="line">          sum+=trans[clusters[i].samples[j]][m];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        clusters[i].center[m]=sum/clusters[i].samples.<span class="built_in">size</span>();</span><br><span class="line">        sum=<span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> clusters;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　用了C++作为实现的代码，python的代码可以参考网上的，有很多。计算距离用的是欧式距离。数据可以自己构造尝试。</p><hr></div><footer class="post-footer"><div class="post-tags"><a href="/tags/MachineLearning/" rel="tag"><i class="fa fa-tag"></i> MachineLearning</a> <a href="/tags/Learning/" rel="tag"><i class="fa fa-tag"></i> Learning</a> <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a> <a href="/tags/Clustering/" rel="tag"><i class="fa fa-tag"></i> Clustering</a> <a href="/tags/K-Means/" rel="tag"><i class="fa fa-tag"></i> K-Means</a></div><div class="post-nav"><div class="post-nav-item"><a href="/Linux/2017-08-13-fedora-lnmp" rel="prev" title="Fedora搭建LNMP环境"><i class="fa fa-chevron-left"></i> Fedora搭建LNMP环境</a></div><div class="post-nav-item"><a href="/Notes/2018-09-11-numpy-function-dot" rel="next" title="numpy.dot()函数">numpy.dot()函数 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="gitalk-container"></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Haniel Farnsworth</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">Symbols count total: </span><span title="Symbols count total">239k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">Reading time total &asymp;</span> <span title="Reading time total">9:58</span></div><div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="external nofollow noopener noreferrer" target="_blank">Hexo</a> & <a href="https://github.com/next-geek/next-geek" class="theme-link" rel="external nofollow noopener noreferrer" target="_blank">Next-geek</a></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script src="/js/local-search.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '27e3eba13ef3780f492b',
      clientSecret: '4e28d0b26bbf1501e220a7d94b983aec4e4c11df',
      repo        : 'CommentsRepo',
      owner       : 'HanielF',
      admin       : ['HanielF'],
      id          : '1ca494c3cae5ccc56aa742e6e9a6038a',
        language: 'en',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});</script></body></html>